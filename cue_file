#!/usr/bin/env python3
# encoding: utf-8

# cue_file
# 2024-03-23 Moonbase59
# 2024-04-11 Moonbase59 - Added liq_cross_start_next
# 2024-04-12 Moonbase59 - Rename `liq_duration` -> `liq_cue_duration`
#                       - Change to create correctly typed JSON (thanks @toots!)
# 2024-04-20 Moonbase59 - optimized skip_analysis for different loudness targets
#                       - allow loudness values as floats
# 2024-04-24 Moonbase59 - completely remove `liq_cross_duration`, so it won’t
#                         be written to file’s tags
# 2024-04-25 Moonbase59 - handle old RG1/mp3gain positive loudness reference
#
# Originally based on an idea and some code by John Warburton (@Warblefly):
#   https://github.com/Warblefly/TrackBoundaries

import os
import tempfile
import subprocess
import argparse
import json
import re
from pathlib import Path

# Default presets
FFMPEG = "ffmpeg"  # location of the ffmpeg binary
FFPROBE = "ffprobe"  # location of the ffprobe binary
TARGET_LUFS = -18.0  # Reference Loudness Target
# -96 dB/LU is "digital silence" for 16-bit audio.
# A "noise floor" of -60 dB/LU (42 dB/LU below -18 target) is a good value to use.
SILENCE = -42.0  # LU below average for cue-in/cue-out trigger ("silence")
OVERLAY_LU = -8.0  # LU below average for overlay trigger (start next song)
# more than LONGTAIL_SECONDS below OVERLAY_LU are considered a "long tail"
LONGTAIL_SECONDS = 15.0
LONGTAIL_EXTRA_LU = -15.0  # reduce 15 dB extra on long tail songs to find overlap point

# minimum set of tags after "read_tags" that must be there before skipping analysis
tags_mandatory = set([
    "duration",
    "liq_cue_in",
    "liq_cue_out",
    "liq_cross_start_next",
    "replaygain_track_gain",
])

# bool() returns True for every nonempty string, so use a function
def is_true(v):
    return v.lower() == 'true'

# these are the tags to check when reading/writing tags from/to files
tags_to_check = {
    "duration": float,
    "liq_cue_duration": float,
    "liq_cue_in": float,
    "liq_cue_out": float,
    "liq_cross_start_next": float,
    "liq_longtail": is_true,
    "liq_cross_duration": float,
    "liq_loudness": float,
    "liq_amplify": float,
    "liq_reference_loudness": float,
    "liq_blankskip": is_true,
    "liq_blank_skipped": is_true,
    "replaygain_track_gain": float,
    "replaygain_reference_loudness": float,
    "r128_track_gain": int,
}

def read_tags(filename, target=TARGET_LUFS, blankskip=False):
    # ffprobe -v quiet -show_entries 'stream=codec_name:stream_tags:format_tags' -print_format json=compact=1 filename
    r = subprocess.run(
        [
            FFPROBE,
            "-v",
            "quiet",
            "-show_entries",
            "stream=codec_name,duration:stream_tags:format_tags",
            "-of",
            "json=compact=1",
            filename,
        ],
        stdout=subprocess.PIPE,
        # stderr=subprocess.STDOUT,
        check=True,
        text=True).stdout

    result = json.loads(r)
    #print(json.dumps(result, indent=2))

    # get tags in stream #0 (mka, opus, etc.)
    try:
        stream_items = result['streams'][0]['tags'].items()
    except KeyError:
        stream_items = {}

    # get tags in format (flac, mp3, etc.)
    try:
        format_items = result['format']['tags'].items()
    except KeyError:
        format_items = {}

    tags_in_stream = {k.lower(): v for k, v in stream_items if k.lower() in tags_to_check}
    tags_in_format = {k.lower(): v for k, v in format_items if k.lower() in tags_to_check}
    # unify, right overwrites left if key in both
    tags_found = tags_in_stream | tags_in_format

    # add duration of stream #0
    try:
        tags_found["duration"] = result['streams'][0]['duration']
    except KeyError:
        try:
            # we might have a video duration (.mka) like "00:07:01.117000000", ignore
            del tags_found["duration"]
        except KeyError:
            pass

    # remove " dB", " LU", " dBFS", and " LUFS" suffixes from tags_found
    def remove_suffix(tags):
        suffixed_tags = [
            "liq_amplify", "liq_loudness", "liq_reference_loudness",
            "replaygain_track_gain", "replaygain_reference_loudness"
        ]
        for tag in suffixed_tags:
            if tag in tags:
                if tags[tag].endswith((" dB", " LU", " dBFS", " LUFS")):
                    number, _, _ = tags[tag].rpartition(" ")
                    tags[tag] = number
        return tags

    # remove suffixes from several tags
    tags_found = remove_suffix(tags_found)

    # create replaygain_track_gain from Opus R128_TRACK_GAIN (ref: -23 LUFS)
    if "r128_track_gain" in tags_found:
        rg = float(tags_found["r128_track_gain"]) / 256 + (target - -23.0)
        tags_found["replaygain_track_gain"] = rg

    # add missing liq_amplify, if we have replaygain_track_gain
    if (not "liq_amplify" in tags_found) and ("replaygain_track_gain" in tags_found):
        tags_found["liq_amplify"] = tags_found["replaygain_track_gain"]

    # convert tag string values to the correct types, listed in tags_to_check
    tags_found = {k: tags_to_check[k](v) for k, v in tags_found.items()}

    # Handle old RG1/mp3gain positive loudness reference
    # "89 dB" (SPL) should actually be -14 LUFS, but as a reference
    # it is usually set equal to the RG2 -18 LUFS reference point
    if (("replaygain_reference_loudness" in tags_found)
        and tags_found["replaygain_reference_loudness"] > 0.0):
        tags_found["replaygain_reference_loudness"] -= 107.0

    # add missing liq_reference_loudness, if we have replaygain_reference_loudness
    if ((not "liq_reference_loudness" in tags_found)
        and ("replaygain_reference_loudness" in tags_found)):
        tags_found["liq_reference_loudness"] = tags_found["replaygain_reference_loudness"]

    # if both liq_cue_in & liq_cue_out available, we can calculate liq_cue_duration
    if "liq_cue_in" in tags_found and "liq_cue_out" in tags_found:
        tags_found["liq_cue_duration"] = tags_found["liq_cue_out"] - tags_found["liq_cue_in"]

    # see if we need a re-analysis
    skip_analysis = tags_mandatory.issubset(tags_found.keys())

    # try to avoid re-analysis if we have enough data but different loudness target
    if (
        skip_analysis
        and "liq_amplify" in tags_found
        and "liq_reference_loudness" in tags_found
    ):
        # adjust liq_amplify by loudness target difference, set reference
        tags_found["liq_amplify"] += (target - tags_found["liq_reference_loudness"])
        tags_found["liq_reference_loudness"] = target
    else:
        # liq_amplify or liq_reference_loudness missing, must re-analyse
        skip_analysis = False

    # if liq_blankskip different from requested, we need a re-analysis
    if (skip_analysis
        and "liq_blankskip" in tags_found
        and (tags_found["liq_blankskip"] != blankskip)
    ):
        skip_analysis = False

    #print(skip_analysis, json.dumps(tags_found, indent=2))
    return skip_analysis, tags_found

def add_missing(tags_found, target=TARGET_LUFS, blankskip=False):
    # we need not check those in tags_mandatory and those calculated by read_tags

    if not "liq_longtail" in tags_found:
        tags_found["liq_longtail"] = False

    #if not "liq_cross_duration" in tags_found:
    #    tags_found["liq_cross_duration"] = tags_found["liq_cue_out"] - tags_found["liq_cross_start_next"]

    if not "liq_amplify" in tags_found:
        tags_found["liq_amplify"] = tags_found["replaygain_track_gain"]

    if not "liq_loudness" in tags_found:
        tags_found["liq_loudness"] = target - tags_found["replaygain_track_gain"]

    if not "liq_blankskip" in tags_found:
        tags_found["liq_blankskip"] = blankskip

    if not "liq_blank_skipped" in tags_found:
        tags_found["liq_blank_skipped"] = False

    if not "liq_reference_loudness" in tags_found:
        tags_found["liq_reference_loudness"] = target

    return tags_found

def analyse(
        filename,
        target=TARGET_LUFS,
        overlay=OVERLAY_LU,
        silence=SILENCE,
        longtail_seconds=LONGTAIL_SECONDS,
        extra=LONGTAIL_EXTRA_LU,
        blankskip=False):
    # ffmpeg -v quiet -i audiofile.ext -vn -af ebur128=target=-18:metadata=1,ametadata=mode=print:file=- -f null null
    # Output:
    # frame:448  pts:2150400 pts_time:44.8
    # lavfi.r128.M=-78.490
    # lavfi.r128.S=-78.566
    # lavfi.r128.I=-18.545
    # lavfi.r128.LRA=5.230
    # lavfi.r128.LRA.low=-23.470
    # lavfi.r128.LRA.high=-18.240

    result = subprocess.run(
        [
            FFMPEG,
            "-v",
            "quiet",
            "-y",
            "-i",
            filename,
            "-vn",
            "-af",
            "ebur128=target=" +
            str(target) +
            ":metadata=1,ametadata=mode=print:file=-",
            "-f",
            "null",
            "null"],
        stdout=subprocess.PIPE,
        # stderr=subprocess.STDOUT,
        check=True,
        text=True).stdout

    measure = []
    # Extract time "t", momentary (last 400ms) loudness "M" and "I" integrated loudness
    # from ebur128 filter. Measured every 100ms.
    # With some file types, like MP3, M can become "nan" (not-a-number),
    # which is a valid float in Python. Usually happens on very silent parts.
    # FIXME: This relies on "I" coming two lines after "M"
    pattern = re.compile(
        r"frame:.*pts_time:\s*(?P<t>\d+\.?\d*)\s*lavfi\.r128\.M=(?P<M>nan|[+-]?\d+\.?\d*)\s*.*\s*lavfi\.r128\.I=(?P<I>nan|[+-]?\d+\.?\d*)",
        flags=re.M)

    for match in re.finditer(pattern, result):
        m = match.groupdict()
        measure.append([float(m["t"]), float(m["M"]), float(m["I"])])

    # range to watch (for later blank skip)
    start = 0
    end = len(measure)

    # get actual duration from last PTS (Presentation Time Stamp)
    # This is the last frame, so the total duration is its PTS + frame length
    # (100ms)
    duration = measure[end-1][0] + 0.1

    # get integrated song loudness from last frame, so we can calculate liq_amplify
    # (the "ReplayGain") from it (difference to desired loudness target)
    loudness = measure[end-1][2]

    # Find cue-in point (loudness above "silence")
    silence_level = loudness + silence
    cue_in_time = 0.0
    for i in range(start, end):
        if measure[i][1] > silence_level:
            cue_in_time = measure[i][0]
            start = i
            break
    # EBU R.128 measures loudness over the last 400ms,
    # adjust to zero if we land before 400ms for cue-in
    cue_in_time = 0.0 if cue_in_time < 0.4 else cue_in_time

    # Instead of simply reversing the list (measure.reverse()), we henceforth
    # use "start" and "end" pointers into the measure list, so we can easily
    # check forwards and backwards, and handle partial ranges better.
    # This is mainly for early cue-outs due to blanks in file ("hidden tracks"),
    # as we need to handle overlaying and long tails correctly in this case.

    cue_out_time = 0.0
    cue_out_time_blank = 0.0

    # Cue-out when silence starts within a song, like "hidden tracks".
    # Check forward in this case, and trust EBU R128’s 400ms to be long enough,
    # checking for loudness going below the defined silence level.
    # NOTE: This shouldn’t be used with TTS-generated jingles and spoken text,
    # because the pauses in speech will trigger the detection and cut off the text!
    if blankskip:
        # print("Checking for blank")
        end_blank = end
        for i in range(start, end):
            if measure[i][1] <= silence_level:
                cue_out_time_blank = measure[i][0]
                end_blank = i+1
                # print(f"Found cue-out blank: {end_blank}, {cue_out_time_blank}")
                break

    # Normal cue-out: check backwards, from the end, for loudness above "silence"
    for i in reversed(range(start, end)):
        if measure[i][1] > silence_level:
            cue_out_time = measure[i][0]
            end = i+1
            # print(f"Found cue-out: {end}, {cue_out_time}")
            break
    # cue out PAST the current frame (100ms) -- no, reverse that
    cue_out_time = max(cue_out_time, duration - cue_out_time)

    # Adjust cue-out and "end" point if we're working with blank detection.
    # Also set a flag (`liq_blank_skipped`) so we can later see if cue-out is early.
    blank_skipped = False
    if blankskip:
        # cue out PAST the current frame (100ms) -- no, reverse that
        #cue_out_time_blank = cue_out_time_blank + 0.1
        # print(f"cue-out blank: {cue_out_time_blank}, cue-out: {cue_out_time}")
        if 0.0 < cue_out_time_blank < cue_out_time:
            cue_out_time = cue_out_time_blank
            blank_skipped = True
        end = end_blank

    # Find overlap point (where to start next song), backwards from end,
    # by checking if song loudness goes below overlay start volume
    cue_duration = cue_out_time - cue_in_time
    start_next_level = loudness + overlay
    start_next_time = 0.0
    for i in reversed(range(start, end)):
        if measure[i][1] > start_next_level:
            start_next_time = measure[i][0]
            break
    start_next_time = max(start_next_time, cue_out_time - start_next_time)

    # We want to keep songs with a long fade-out intact, so if the calculated
    # overlap is longer than the "longtail_seconds" time, we check again, by reducing
    # the loudness to look for by an additional "extra" amount of LU
    longtail = False

    if (cue_out_time - start_next_time) > longtail_seconds:
        longtail = True
        start_next_level = loudness + overlay + extra
        start_next_time = 0.0
        for i in reversed(range(start, end)):
            if measure[i][1] > start_next_level:
                start_next_time = measure[i][0]
                break
        start_next_time = max(start_next_time, cue_out_time - start_next_time)

    # Now that we know where to start the next song, calculate Liquidsoap's
    # cross duration from it, allowing for an extra 0.1s of overlap -- no, reverse
    # (a value of 0.0 is invalid in Liquidsoap)
    cross_duration = cue_out_time - start_next_time

    # We now also return start_next_time

    # NOTE: Liquidsoap doesn’t currently accept `liq_cross_duration=0.`,
    # or `liq_cross_start_next == liq_cue_out`, but this can happen.
    # We adjust for that in the Liquidsoap protocol, because other AutoDJ
    # applications might want the correct values.

    # return a dict
    return ({
        "duration": duration,
        "liq_cue_duration": cue_duration,
        "liq_cue_in": cue_in_time,
        "liq_cue_out": cue_out_time,
        "liq_cross_start_next": start_next_time,
        "liq_longtail": longtail,
        #"liq_cross_duration": cross_duration,
        "liq_loudness": loudness,
        "liq_amplify": (target - loudness),
        "liq_reference_loudness": target,
        "liq_blankskip": blankskip,
        "liq_blank_skipped": blank_skipped
    })

def write_tags(filename, tags={}):
    # Add the liq_* tags (and only these)
    # Don’t touch replaygain_track_gain or R128_TRACK_GAIN
    # NOTE: This won’t work with all file types! (.m4a)
    filename = Path(filename)

    # This doesn’t work cross-device!
    #temp_file_handle, temp = tempfile.mkstemp(prefix="cue_file.", suffix=filename.suffix)
    # So we use the same folder, to be able to do an atomic move.
    temp = filename.with_suffix('.tmp' + filename.suffix)
    #print(temp)

    # copy only `liq_*`, float with 2 decimals, bools and strings lowercase
    tags_new = {k: "{:.2f}".format(v)
        if isinstance(v, float) else str(v).lower()
        for k, v in tags.items() if k.startswith("liq_")
    }
    # add the " dB"
    tags_new["liq_amplify"] += " dB"
    tags_new["liq_loudness"] += " dB"
    tags_new["liq_reference_loudness"] += " LUFS"
    #print(temp, json.dumps(tags_new, indent=2))

    metadata_args = []
    for k, v in tags_new.items():
        metadata_args.extend(['-metadata', f'{k}={v}'])
    #print(metadata_args)

    args = [
        FFMPEG,
        '-v', 'quiet',
        '-y',
        '-i', str(filename.absolute()),
        '-map_metadata', '0',
        *metadata_args,
        '-c', 'copy',
        str(temp)
    ]
    proc = subprocess.run(args, stdout=subprocess.PIPE, check=True)

    # mv temp original; atomic
    os.replace(str(temp), str(filename.absolute()))

    return

# CLI command parser and help text
parser = argparse.ArgumentParser(
    description="Return cue-in, cue-out, overlay and replaygain data for an audio " \
    "file as JSON. To be used with my Liquidsoap \"autocue:\" protocol.",
    epilog="Please report any issues to https://github.com/Moonbase59/autocue/issues",
    formatter_class=argparse.ArgumentDefaultsHelpFormatter)

parser.add_argument("file", help="File to be processed")
parser.add_argument("-t", "--target", help="LUFS reference target",
                    default=TARGET_LUFS, type=float)
parser.add_argument(
    "-s",
    "--silence",
    help="LU/dB below integrated track loudness for cue-in & cue-out points " \
    "(silence removal at beginning & end of a track)",
    default=SILENCE,
    type=float)
parser.add_argument(
    "-o",
    "--overlay",
    help="LU/dB below integrated track loudness to trigger next track",
    default=OVERLAY_LU,
    type=float)
parser.add_argument(
    "-l",
    "--longtail",
    help="More than so many seconds of calculated overlay duration are considered " \
    "a long tail, and will force a recalculation using --extra, thus keeping long " \
    "song endings intact",
    default=LONGTAIL_SECONDS,
    type=float)
parser.add_argument(
    "-x",
    "--extra",
    help="Extra LU/dB below overlay loudness to trigger next track for songs " \
    "with long tail",
    default=LONGTAIL_EXTRA_LU,
    type=float)
parser.add_argument(
    "-b",
    "--blankskip",
    help="Skip blank (silence) within song (get rid of \"hidden tracks\"). " \
    "Sets the cue-out point to where the silence begins. Don't use this with " \
    "spoken or TTS-generated text, as it will often cut the message short.",
    default=False,
    action='store_true')
parser.add_argument(
    "-w",
    "--write",
    help="Write Liquidsoap liq_* tags to file. Use with care, as ffmpeg can't " \
    "write all tags to all file types! Ensure you have enough free space to " \
    "hold a copy of the original file.",
    default=False,
    action='store_true')
parser.add_argument(
    "-f",
    "--force",
    help="Force re-calculation, even if tags exist",
    default=False,
    action='store_true')

args = parser.parse_args()
args.target = float(args.target)

skip_analysis, tags_found = read_tags(args.file, args.target, args.blankskip)

if args.force or not skip_analysis:
    result = analyse(
        filename=args.file,
        target=args.target,
        overlay=args.overlay,
        silence=args.silence,
        longtail_seconds=args.longtail,
        extra=args.extra,
        blankskip=args.blankskip
    )
else:
    result = add_missing(tags_found, args.target, args.blankskip)

#print(result)

if args.write:
    write_tags(args.file, result)

# prepare JSON result
# we use "dB" instead of "LU" units, because LS & others don’t understand "LU"
liq_result = {
    "duration": result['duration'],
    "liq_cue_duration": result['liq_cue_duration'],
    "liq_cue_in": result['liq_cue_in'],
    "liq_cue_out": result['liq_cue_out'],
    "liq_cross_start_next": result['liq_cross_start_next'],
    "liq_longtail": result["liq_longtail"],
    #"liq_cross_duration": result['liq_cross_duration'],
    "liq_loudness": f"{result['liq_loudness']:.2f} dB",
    "liq_amplify": f"{result['liq_amplify']:.2f} dB",
    "liq_reference_loudness": f"{result['liq_reference_loudness']:.2f} LUFS",
    "liq_blankskip": result['liq_blankskip'],
    "liq_blank_skipped": result['liq_blank_skipped'],
}

# output compact (one line) JSON, for use in Liquidsoap "autocue:" protocol
json_output = json.dumps(liq_result)
print(json_output)
